{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "226d1734",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import random\n",
    "import string\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e53aa2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')  \n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cde6bc1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Define Training Data (Chatbot Knowledge Base)\n",
    "corpus = \"\"\"Hello! How can I help you today? \n",
    "I am a chatbot created to assist with basic queries. \n",
    "You can ask me about general topics. \n",
    "I can help with programming, weather updates, and small talk.\n",
    "If you need specific help, please specify your question.\n",
    "I do not have access to live data, but I can give useful information. \n",
    "How are you today? \n",
    "Tell me about your favorite hobby.\n",
    "Goodbye! Have a great day!\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "21171693",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Preprocess Text (Tokenization & Lemmatization)\n",
    "sentence_tokens = nltk.sent_tokenize(corpus)  # Sentence-level tokenization\n",
    "word_tokens = nltk.word_tokenize(corpus)  # Word-level tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a16a523",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = nltk.WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "05362423",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    tokens = nltk.word_tokenize(text.lower())  # Convert to lowercase & tokenize\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens if word not in string.punctuation]  # Lemmatize words\n",
    "    return \" \".join(tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cb0afce5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot: Hello! Type 'bye' to exit.\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Define a Function to Generate a Response\n",
    "def chatbot_response(user_input):\n",
    "    user_input = preprocess_text(user_input)\n",
    "    sentence_tokens.append(user_input)  # Add user query to corpus\n",
    "\n",
    "    # Convert text to numerical representation using TF-IDF\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    tfidf_matrix = vectorizer.fit_transform(sentence_tokens)\n",
    "    \n",
    "    # Compute similarity between user input and all sentences in corpus\n",
    "    similarity_scores = cosine_similarity(tfidf_matrix[-1], tfidf_matrix[:-1])\n",
    "    sentence_tokens.pop()  # Remove user input from corpus after processing\n",
    "\n",
    "    # Find the best matching response\n",
    "    response_idx = np.argmax(similarity_scores)  # Get the index of the highest similarity\n",
    "    confidence = similarity_scores[0, response_idx]\n",
    "\n",
    "    if confidence < 0.3:  # Set a threshold for relevance\n",
    "        return \"I'm sorry, I don't understand that.\"\n",
    "\n",
    "    return sentence_tokens[response_idx]\n",
    "\n",
    "# Step 4: Implement Chat Loop\n",
    "print(\"Chatbot: Hello! Type 'bye' to exit.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2049f4c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You: hello\n",
      "Chatbot: Hello!\n",
      "You: tell me about\n",
      "Chatbot: Tell me about your favorite hobby.\n",
      "You: dancing\n",
      "Chatbot: I'm sorry, I don't understand that.\n",
      "You: exit\n",
      "Chatbot: Goodbye! Have a great day!\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    user_input = input(\"You: \")\n",
    "    if user_input.lower() in ['bye', 'exit', 'quit']:\n",
    "        print(\"Chatbot: Goodbye! Have a great day!\")\n",
    "        break\n",
    "    print(\"Chatbot:\", chatbot_response(user_input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5ffe266",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
